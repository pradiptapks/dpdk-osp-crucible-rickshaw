#!/bin/bash
# -*- mode: sh; indent-tabs-mode: nil; sh-basic-offset: 4 -*-
# vim: autoindent tabstop=4 shiftwidth=4 expandtab softtabstop=4 filetype=bash
set -u

# This script implements the 'remotehost' endpoint for rickshaw.  It runs 1 or more
# clients and servers for as many benchmark interations/samples as required
# for a single invocation of rickshaw.
# 
#
# Usage: (as called by rickshaw-run)
#
# remotehost
# [--validate]
# --endpoint-label
# --run-id
# --base-run-dir
# --image
# --roadblock-server
# --roadblock-id
# --roadblock-passwd
# --endpoint-opts=client:n-m,o-p,server:n-m,o-p,host:<remote-host>,userenv:<distro>,host-mount:<dirpath>
#
# Note: When specifying a remotehost endpoint on an invocation of rickshaw-run
# (or crucible run <benchmark>) the following format is used:
#
# --endpoint remotehost,client:<range>,server:<range>,host:<remote-hostname>
#
# and the remaining options are handled by rickshaw-run
#
# If --validate is used all options after client/server will be ignored

this_endpoint_dir=$(dirname `readlink -e $0` | sed -e 'sX/binXX')
endpoint_base_dir=$(cd $this_endpoint_dir >/dev/null && cd .. && /bin/pwd)
if [ -e "$endpoint_base_dir/base" ]; then
    . "$endpoint_base_dir/base"
else
    echo "Could not find endpoint source file "$endpoint_base_dir/base", exiting"
    exit 1
    exit
fi

chroot_rbind_mounts="proc dev sys lib/modules usr/src boot var/run"

endpoint_name="remotehost"
image_cache_size=3
userenv="rhubi8"
user="root"
declare -A cpuPartitioning
declare -A numaNode
declare -A osruntime
osruntime[default]="chroot"
host_mounts=""

function endpoint_remotehost_test_stop() {
    echo "Running endpoint_remotehost_test_stop"
}

function endpoint_remotehost_test_start() {
    local msgs_dir="$1"; shift
    local test_id="$1"; shift
    local tx_msgs_dir="$1"; shift
    echo "Running endpoint_remotehost_test_start"

    local this_msg_file="$msgs_dir/$test_id:endpoint-start.json"
    if [ -e $this_msg_file ]; then
        echo "Found $this_msg_file"
        # We are looking for a specific type of message, where a server is providing a
        # { "user-object": { "svc": { "ip: "<ipaddr>", "ports": [ ... ] } } }
        # This is the only type of message that an endpoint processes.
        # The message must come from a benchmark-server hosted on *this* endpoint
        #
        # Extract the cs-label (server-n, client-y) and the ports this benchmark is using
        # server-1 30002 30003
        cat $this_msg_file | jq -r '.received[] | if .payload.message.command == "user-object" and .payload.message."user-object".svc.ports then [.payload.sender.id, .payload.message."user-object".svc.ip, .payload.message."user-object".svc.ports  ] | flatten | tostring else null end' | grep -v null | sed -e 's/"//g' -e 's/\[//' -e 's/\]//' -e 's/,/ /g' >"$endpoint_run_dir/ip-ports.txt"
        while read -u 9 line; do
            # For a benchmark server in a remotehost endpoint, the only
            # thing that might be necessary to allow access from a
            # client is to punch a hole in the firewall, if one exists.
            # The current implementation of this endpoint does not do
            # that yet.  The only function here is to relay the IP/port
            # information found in the received message to the client.
            echo "line: $line"
            local name=`echo $line | awk '{print $1}'`
            line=`echo $line | sed -e s/^$name//`
            local ip=`echo $line | awk '{print $1}'`
            line=`echo $line | sed -e s/^$ip//`
            local ports="$line"
            local port_list=""
            local count=1
            for port in $ports; do
                if [ $count -gt 1 ]; then
                    port_list+=", $port"
                else
                    port_list="$port"
                fi
                let count=$count+1
            done

            local server_outside_endpoint=1
            echo "servers from this endpoint: ${servers[@]}"
            if echo ${servers[@]} | grep -q $name; then
                echo "This server, $name, is running from this endpoint"
                server_outside_endpoint=0
            fi

            local client_outside_endpoint=1
            matching_client=`echo $name | sed -e s/server/client/`
            if echo ${clients[@]} | grep -q $matching_client; then
                echo "Matching client, $matching_client, is running from this endpoint"
                client_outside_endpoint=0
            fi

            if [ $client_outside_endpoint -eq 1 -a $server_outside_endpoint -eq 0 ]; then
                echo "Going to punch hole through firewall (some day...)"
                # TODO: actually punch hole through firewall (also undo on endpoint_remotehost_test_stop)
                # Now we can construct a message to be sent to the client about the IP and ports for the server
                echo "Creating a message to send to the client ($matching_client) with IP and port info"
                echo -n '{"recipient":{"type":"follower","id":"client-' >"$tx_msgs_dir/service-ip-$name.json"
                echo $name | awk -F- '{print $2}' | tr -d "\n" >>"$tx_msgs_dir/service-ip-$name.json"
                echo -n '"},"user-object":{"svc":{"ip": "'$ip'", ' >>"$tx_msgs_dir/service-ip-$name.json"
                echo '"ports": ['$port_list']}}}' >>"$tx_msgs_dir/service-ip-$name.json"
            fi
        done 9< "$endpoint_run_dir/ip-ports.txt"
    else
        echo "Could not find $this_msg_file"
    fi
}

function cleanup_osruntime() {
    local container_name container_image this_cs_label tmp_osruntime data_file
    echo "Doing osruntime cleanup"
    echo
    echo "All mounts on this remote host:"
    do_ssh $user@$host mount
    echo
    echo "All podman pods:"
    do_ssh $user@$host podman ps --all
    echo
    echo "All podman container mounts:"
    do_ssh $user@$host podman mount
    echo

    for this_cs_label in ${clients[@]} ${servers[@]}; do
        tmp_osruntime=${osruntime[default]}
        set +u
        if [ ! -z "${osruntime[$this_cs_label]}" ]; then
            tmp_osruntime=${osruntime[$this_cs_label]}
        fi
        set -u

        if [ "${tmp_osruntime}" == "chroot" ]; then
            data_file=${endpoint_run_dir}/chroot-container-mount.txt
            if [ -e ${data_file} ]; then
                while read tmp_cs_label container_mount; do
                    if [ "${this_cs_label}" == "${tmp_cs_label}" ]; then
                        for fs in ${chroot_rbind_mounts}; do
                            echo "Removing ${fs} from ${container_mount}"
                            do_ssh ${user}@${host} umount --verbose --recursive ${container_mount}/${fs}
                        done
                    fi
                done < ${data_file}
            else
                echo "WARNING: the file with container base mount [${data_file}] could not be found"
            fi

            data_file=$endpoint_run_dir/chroot-container-id.txt
            if [ -e ${data_file} ]; then
                while read tmp_cs_label container_id; do
                    if [ "${this_cs_label}" == "${tmp_cs_label}" ]; then
                        echo "Removing container with id [${container_id}]"
                        do_ssh ${user}@${host} podman rm ${container_id}
                    fi
                done < ${data_file}
            else
                echo "WARNING: the file with container base mount [${data_file}] could not be found"
            fi
        elif [ "${tmp_osruntime}" == "podman" ]; then
            container_name="${endpoint_label}_${run_id}_${this_cs_label}_${tmp_osruntime}"
            do_ssh $user@$host podman rm ${container_name}
        fi
    done

    # manage container image cache on the host
    echo "Performing container image cache management:"
    ${endpoint_base_dir}/remotehost/container-image-manager --remote-host ${user}@${host} --cache-size ${image_cache_size} --debug 0
    echo

    echo "Remaining containers on this remote host:"
    do_ssh $user@$host podman ps --all
    echo

    echo "Remaining container mounts on this remote host:"
    do_ssh $user@$host podman mount
    echo

    echo "Remaining container images on this remote host:"
    do_ssh $user@$host podman images --all
    echo
}

function process_remotehost_opts() {
    local endpoint_opts this_opt arg val
    endpoint_opts="$1"
    for this_opt in `echo $endpoint_opts | sed -e 's/,/ /g'`; do
        arg=`echo $this_opt | awk -F: '{print $1}'`
        # The $val may have : in it, so don't use awk to get only the second field
        val=`echo $this_opt | sed -e s/^$arg://`
        case "$arg" in
            client|server|clients|servers|profiler)
                addto_clients_servers "$arg" "$val"
                ;;
            osruntime)
                # osruntime is per engine:
                # option format:: osruntime:<engine-label>:<value>
                # <engine-label> can be 'default' to apply to any engine that is not explicitly specified
                # for backwards compability values in the form of 'osruntime:<value>' will map to 'osruntime:default:<value>'
                #TODO: validate correct format of <engine-label>

                # backwards compability transformation
                if ! echo "${val}" | grep -q -e '[a-zA-Z0-9\-]:[a-zA-Z0-9\-]'; then
                    val="default:${val}"
                fi

                name=$(echo "${val}" | awk -F: '{ print $1 }')
                value=$(echo "${val}" | awk -F: '{ print $2 }')

                if [ -z "${name}" -o -z "${value}" ]; then
                    exit_error "Could not properly decode osruntime for '${val}'"
                else
                    case "${value}" in
                        chroot|podman)
                            osruntime[${name}]=${value}
                            ;;
                        *)
                            exit_error "osruntime '${value}' for '${name}' not supported"
                            ;;
                    esac
                fi
                ;;
            numa-node)
                # node-node is per engine:
                # option format:: numa-node:<engine-label>:<value>
                # <engine-label> can be 'default' to apply to any engine that is not explicitly specified
                #TODO: validate correct format of <engine-label>
                name=`echo $val | awk -F: '{ print $1 }'`
                value=`echo $val | awk -F: '{ print $2 }'`
                if [ ! -z "$name}" -a ! -z "$value" ]; then
                    numaNode[$name]=$value
                else
                    exit_error "Could not properly decode numa-node for '$val'"
                fi
                ;;
            userenv)
                userenv=$val
                ;;
            host)
                host=$val
                if [ -z "$controller_ipaddr" ]; then
                    controller_ipaddr=`get_controller_ip $host`
                fi
                ;;
            controller-ip)
                controller_ipaddr=$val
                ;;
            user)
                user=$val
                ;;
            host-mount)
                host_mounts+=" $val"
                ;;
            cpu-partitioning)
                # cpu-partitioning is per engine:
                # option format:: cpu-partitioning:<engine-label>:<value>
                # <engine-label> can be 'default' to apply to any engine that is no explicitly specified
                #TODO: validate correct format of <label-label>
                name=`echo $val | awk -F: '{ print $1 }'`
                value=`echo $val | awk -F: '{ print $2 }'`
                if [ ! -z "${name}" -a ! -z "${value}" ]; then
                    cpuPartitioning[$name]=$value
                else
                    exit_error "Could not properly decode cpu-partitioning for '$val'"
                fi
                ;;
            disable-tools)
                disable_tools="$val"
                ;;
            image-cache-size)
                image_cache_size=$val
                ;;
            *)
                if echo $arg | grep -q -- "="; then
                    echo "You can't use a \"=\" for assignment in endpoint options"
                    echo "You must use \":\", like `echo $arg | sed -e 's/=/:/'`"
                fi
                exit_error "remotehost endpoint option [$arg] not supported"
                ;;
        esac
    done
    if [ "$do_validate" != "1" ]; then
        remote_base_dir="/var/lib/crucible"
        remote_dir="${remote_base_dir}/${endpoint_label}_${run_id}"
        remote_cfg_dir="${remote_dir}/cfg"
        remote_logs_dir="${remote_dir}/logs"
        remote_data_dir="${remote_dir}/data/tmp"
    fi
}

function remotehost_req_check() {
    verify_ssh_login $user $host
    do_ssh $user@$host podman --version >/dev/null 2>&1 ||\
        do_ssh $user@$host yum install -y podman >/dev/null 2>&1 ||\
        exit_error "Podman not installed and could not install it" 
    # Validation returns what clients and servers would be used and the userenv
    if [ "$do_validate" == 1 ]; then
        echo_clients_servers
        echo "userenv $userenv"
        exit
    fi
}

function launch_osruntime() {
    local this_cs_label this_cs_log_file base_cmd cs_cmd cs_rb_env env_file
    local env_opts existing_container container_id container_mount container_name fs
    local total_cpu_partitions tmp_osruntime

    # create working directories
    do_ssh $user@$host /bin/mkdir -p $remote_cfg_dir
    do_ssh $user@$host /bin/mkdir -p $remote_logs_dir
    do_ssh $user@$host /bin/mkdir -p $remote_data_dir

    echo "ensuring container image is pulled to $host"
    do_ssh $user@$host podman pull $image

    echo "Recording container image usage"
    do_ssh $user@$host "echo '$image $(date -u +%s)' >> ${remote_base_dir}/remotehost-container-image-census"

    echo "$image" >$endpoint_run_dir/chroot-container-image.txt

    total_cpu_partitions=0
    for this_cs_label in ${clients[@]} ${servers[@]}; do
        set +u
        cpu_partitioning=0
        if [ ! -z "${cpuPartitioning[$this_cs_label]}" ]; then
            cpu_partitioning=${cpuPartitioning[$this_cs_label]}
        elif [ ! -z "${cpuPartitioning[default]}" ]; then
            cpu_partitioning=${cpuPartitioning[default]}
        fi
        set -u

        if [ "${cpu_partitioning}" == "1" ]; then
            (( total_cpu_partitions++ ))
        fi
    done

    # For each client and server launch the actual script which will run it.
    count=1
    for this_cs_label in ${clients[@]} ${servers[@]} ${collectors[@]}; do
        tmp_osruntime=${osruntime[default]}
        set +u
        if [ ! -z "${osruntime[$this_cs_label]}" ]; then
            tmp_osruntime=${osruntime[$this_cs_label]}
        fi
        set -u

        container_name="${endpoint_label}_${run_id}_${this_cs_label}_${tmp_osruntime}"
        existing_container=`do_ssh $user@$host podman ps --all --format "{{.Names}}" | grep ^$container_name$`
        if [ ! -z "$existing_container" ]; then
            echo "WARNING: found existing container '$existing_container', deleting"
            do_ssh $user@$host podman rm $container_name
        fi
        this_cs_log_file="$this_cs_label.txt"

        set +u
        cpu_partitioning=0
        if [ ! -z "${cpuPartitioning[$this_cs_label]}" ]; then
            cpu_partitioning=${cpuPartitioning[$this_cs_label]}
        elif [ ! -z "${cpuPartitioning[default]}" ]; then
            cpu_partitioning=${cpuPartitioning[default]}
        fi
        set -u

        set +u
        numa_node=-1
        if [ ! -z "${numaNode[$this_cs_label]}" ]; then
            numa_node=${numaNode[$this_cs_label]}
        elif [ ! -z "${numaNode[default]}" ]; then
            numa_node=${numaNode[default]}
        fi
        set -u

        if [ $count -gt 1 ]; then
            # Only the first client/server needs to run tools
            echo "Skipping tools execution on $this_cs_label because a previous client/server is running tools on this host"
            this_disable_tools="1"
        else
            this_disable_tools="$disable_tools"
        fi

        if [ "${tmp_osruntime}" == "chroot" ]; then
            echo "using chroot"

            echo "Adding mount for chroot osruntime"
            container_id=$(do_ssh ${user}@${host} podman create --name ${container_name} ${image})
            echo "container_id: ${container_id}"
            echo "${this_cs_label} ${container_id}" >>${endpoint_run_dir}/chroot-container-id.txt
            container_mount=$(do_ssh ${user}@${host} podman mount "${container_id}")
            echo "container_mount: ${container_mount}"
            echo "${this_cs_label} ${container_mount}" >>${endpoint_run_dir}/chroot-container-mount.txt
            echo "container_name: $container_name"
            echo "${this_cs_label} ${container_name}" >>${endpoint_run_dir}/chroot-container-name.txt
            if [ ! -z "${container_mount}" ]; then
                echo "Container mount: ${container_mount}"
                # Allow the user to more easily inspect failed runs
                echo "Mapping container /tmp to host ${remote_data_dir}"
                do_ssh ${user}@${host} mkdir -p ${container_mount}/tmp
                do_ssh ${user}@${host} mount --verbose --options bind ${remote_data_dir} ${container_mount}/tmp
                echo "Adding host directories to container mount"
                if [ "${host_mounts}" != "" ]; then
                    local oldIFS=${IFS}
                    IFS=" "
                    for fs in ${host_mounts}; do
                        chroot_rbind_mounts+=" ${fs}"
                    done
                    IFS=${oldIFS}
                fi
                for fs in ${chroot_rbind_mounts}; do
                    echo "Adding ${fs} to ${container_mount}"
                    do_ssh ${user}@${host} mkdir -p ${container_mount}/${fs}
                    do_ssh ${user}@${host} mount --verbose --options rbind /${fs} ${container_mount}/${fs}
                    do_ssh ${user}@${host} mount --verbose --make-rslave ${container_mount}/${fs}
                    echo
                done
                # for chroot osruntime we can also simply copy the ssh key
                echo "Copying ssh key to ${user}@${host}:${container_mount}/tmp/ for chroot runtime"
                pushd "${config_dir}" >/dev/null
                do_scp "" "rickshaw_id.rsa" "${user}@${host}" "${container_mount}/tmp/"
                popd >/dev/null
                do_ssh ${user}@${host} /bin/cp /etc/hosts ${container_mount}/etc/
                do_ssh ${user}@${host} /bin/cp /etc/resolv.conf ${container_mount}/etc/
            else
                echo "Container mount not found, exiting"
                exit 1
            fi

            base_cmd="/usr/local/bin/bootstrap"
            base_cmd+=" --rickshaw-host=$controller_ipaddr"
            base_cmd+=" --endpoint-run-dir=$endpoint_run_dir"
            base_cmd+=" $cs_rb_opts"
            base_cmd+=" --cs-label=$this_cs_label"
            base_cmd+=" --base-run-dir=$base_run_dir"
            base_cmd+=" --endpoint=remotehost"
            base_cmd+=" --osruntime=${tmp_osruntime}"
            base_cmd+=" --max-sample-failures=$max_sample_failures"
            base_cmd+=" --max-rb-attempts=$max_rb_attempts"
            base_cmd+=" --cpu-partitions=${total_cpu_partitions}"
            base_cmd+=" --cpu-partition-index=${count}"
            base_cmd+=" --cpu-partitioning=$cpu_partitioning"
            base_cmd+=" --engine-script-start-timeout=$engine_script_start_timeout"
            base_cmd+=" --disable-tools=$this_disable_tools"
            if [ $numa_node -gt -1 ]; then
                base_cmd="numactl -N $numa_node -m $numa_node $base_cmd"
            fi

            # Note that --endpoint-run value must be hard-coded to /endpoint-run becaue of chroot
            # Same will be true for running podman
            cs_cmd="nohup chroot $container_mount $base_cmd >$remote_logs_dir/$this_cs_log_file &"
        elif [ "${tmp_osruntime}" == "podman" ]; then
            echo "using podman"

            env_file="${this_cs_label}_env.txt"
            ssh_id=$(sed -z 's/\n/\\n/g' ${config_dir}/rickshaw_id.rsa)

            echo "rickshaw_host=$controller_ipaddr"         >> ${endpoint_run_dir}/${env_file}
            echo "endpoint_run_dir=$endpoint_run_dir"       >> ${endpoint_run_dir}/${env_file}
            echo "cs_label=$this_cs_label"                  >> ${endpoint_run_dir}/${env_file}
            echo "base_run_dir=$base_run_dir"               >> ${endpoint_run_dir}/${env_file}
            echo "cpu_partitioning=$cpu_partitioning"       >> ${endpoint_run_dir}/${env_file}
            echo "cpu_partitions=${total_cpu_partitions}"   >> ${endpoint_run_dir}/${env_file}
            echo "cpu_partition_index=${count}"             >> ${endpoint_run_dir}/${env_file}
            echo "endpoint=remotehost"                      >> ${endpoint_run_dir}/${env_file}
            echo "osruntime=${tmp_osruntime}"               >> ${endpoint_run_dir}/${env_file}
            echo "max_sample_failures=$max_sample_failures" >> ${endpoint_run_dir}/${env_file}
            echo "max_rb_attempts=$max_rb_attempts"         >> ${endpoint_run_dir}/${env_file}
            echo "ssh_id=${ssh_id}"                         >> ${endpoint_run_dir}/${env_file}
            echo "disable_tools=$this_disable_tools"        >> ${endpoint_run_dir}/${env_file}

            for cs_rb_opt in $cs_rb_opts; do
                arg=$(echo $cs_rb_opt | awk -F'=' '{print $1}')
                value=$(echo $cs_rb_opt | awk -F'=' '{print $2}')

                arg=$(echo ${arg} | sed -e 's/^--//' -e 's/-/_/g' )

                echo "${arg}=${value}"                      >> ${endpoint_run_dir}/${env_file}
            done

            if pushd ${endpoint_run_dir} >/dev/null; then
                echo "Copying ${endpoint_run_dir}/${env_file} to ${user}@${host}:${remote_cfg_dir}"
                do_scp "" "${env_file}" "${user}@${host}" "${remote_cfg_dir}"

                popd >/dev/null
            else
                echo "Failed to pushd to ${endpoint_run_dir} to scp env file"
                exit 1
            fi

            cs_cmd="podman run"
            cs_cmd+=" --detach=true"
            cs_cmd+=" --name=${container_name}"
            cs_cmd+=" --env-file ${remote_cfg_dir}/${env_file}"
            cs_cmd+=" --privileged"
            cs_cmd+=" --ipc=host"
            cs_cmd+=" --pid=host"
            cs_cmd+=" --net=host"
            cs_cmd+=" --security-opt=label=disable"
            cs_cmd+=" --mount=type=bind,source=${remote_data_dir},destination=/tmp"
            cs_cmd+=" --mount=type=bind,source=/lib/modules,destination=/lib/modules"
            cs_cmd+=" --mount=type=bind,source=/usr/src,destination=/usr/src"
            if [ "$host_mounts" != "" ]; then
                local oldIFS=$IFS
                IFS=" "
                for fs in $host_mounts; do
                   cs_cmd+=" --mount=type=bind,source=$fs,destination=$fs"
                done
                IFS=$oldIFS
            fi
            cs_cmd+=" ${image}"
        fi

        echo -e "About to run:\n${cs_cmd}\n"
        do_ssh $user@$host "${cs_cmd}"
        ssh_rc=$?
        if [ ${ssh_rc} -gt 0 ]; then
            echo "running ${osruntime} failed"
            exit 1
        fi

        let count=$count+1
    done
    echo "This endpoint deployed"
    echo
}

function move_remotehost_logs() {
    local this_cs_label remote_cs_log_file container_name delete_remote_dir
    delete_remote_dir=0
    mkdir -p "$engine_logs_dir"
    for this_cs_label in ${clients[@]} ${servers[@]}; do
        tmp_osruntime=${osruntime[default]}
        set +u
        if [ ! -z "${osruntime[$this_cs_label]}" ]; then
            tmp_osruntime=${osruntime[$this_cs_label]}
        fi
        set -u

        if [ "${tmp_osruntime}" == "chroot" ]; then
            delete_remote_dir=1
            remote_cs_log_file="$remote_logs_dir/$this_cs_label.txt"
            pushd / >/dev/null
            do_scp "$user@$host" "$remote_cs_log_file" "" / && \
                mv $remote_cs_log_file $engine_logs_dir
            popd >/dev/null
        elif [ "${tmp_osruntime}" == "podman" ]; then
            container_name="${endpoint_label}_${run_id}_${this_cs_label}_${tmp_osruntime}"
            do_ssh $user@$host podman logs ${container_name} > "${engine_logs_dir}/${this_cs_label}.txt"
        fi
    done
    if [ "${delete_remote_dir}" == "1" ]; then
        do_ssh ${user}@${host} /bin/rm -r ${remote_dir}
    fi
}

function endpoint_remotehost_cleanup() {
    move_remotehost_logs
    cleanup_osruntime
}

process_opts $@
process_remotehost_opts $endpoint_opts
init_common_dirs
load_settings
remotehost_req_check
base_req_check
launch_osruntime
process_roadblocks remotehost

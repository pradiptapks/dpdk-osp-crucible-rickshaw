#!/usr/bin/env bash
# vim: autoindent tabstop=4 shiftwidth=4 expandtab softtabstop=4 filetype=bash

# This script implements the 'k8s' endpoint for rickshaw.  It runs 1 or more
# clients (and no servers, yet) for as many benchmark interations/samples as required
# for a single invocation of rickshaw.  Like all enpoints, this is meant to be used
# with other endpoints for creating multi-cloud tests.
#
# Usage:
# local [--validate] --endpoint-opts=host=<host>,user=<user>,client:n-m,o-p,server:n-m,o-p 
#                    --run-id <id> --base-run-dir --image <location>
#                    --roadblock-server <host> --roadblock-id <id> --roadblock-passwd=<passwd>
#
# If --validate is used all options after client/server will be ignored
#
# TODO: This endpoint script was copied from 'local' endpoint and has some common function.
#       Some of that code could probably be consolidated into a library or utilities.
#       Utilities may work better since other endpoint may be written in a different language.
# TODO: There are a significant number of features we need to implement for pod preferences:
#       - node placement for pods/containers
#       - multus support
#       - pod requests and limits
#       - running benchmark servers and setting up the service and router
#       - containers/pod options
#       - implement tool execution outside the client/server pods (on workers and masters with
#         privileged pods)
#       - collecting information of pod creation and execution
#       - implementing a system info collection of a k8s cluster
#       - using a user-definable container registry for container image sourcing
#         - this is hard-coded right now
#         - rickshaw needs changes to publish locally built images (from workshop) to the user's
#           registry
#         - all endpoint scripts will need to make this change when rickshaw supports this
#
# All of the functions that a client-server-script performs works in this endpoint, such as:
# - benchmark iteration/sample execution
# - using a container image which has the required software
# - tool execution
# - synchronization of execution
# - sending tool and benchmark data back to the controller (where this endpoint script runs)

# Source the base file for common functions and config
this_endpoint_dir=$(dirname `readlink -e $0` | sed -e 'sX/binXX')
endpoint_base_dir=$(cd $this_endpoint_dir >/dev/null && cd .. && /bin/pwd)
if [ -e "$endpoint_base_dir/base" ]; then
    . "$endpoint_base_dir/base"
else
    echo "Could not find endpoint source file "$endpoint_base_dir/base", exiting"
    exit 1
    exit
fi
endpoint_name="k8s"
# TODO: instead of using a prefix in the pods' names, use a unique k8s project
pod_prefix="rickshaw"
userenv="rhubi8"

function k8s_req_check() {
    k8s_kubeconfig=`ssh -o StrictHostKeyChecking=no $k8s_user@$k8s_host env | grep ^KUBECONFIG | awk -F"KUBECONFIG=" '{print $2}'`
    if [ -z "$k8s_kubeconfig" ]; then
        echo "[ERROR]KUBECONFIG on k8s host $k8s_host not defined"
        exit 1
    fi
    k8s_kubectl=`ssh -o StrictHostKeyChecking=no $k8s_user@$k8s_host kubectl 2>&1`
    if [ $? -gt 0 ]; then
        exit_error "Could not run kubectl on k8s host: $k8s_kubectl"
    fi
    # Also exit if asking for servers even in not in --validate
    if [ ${#servers[@]} -gt 0 ]; then
        echo "[ERROR]This endpoint does not support servers yet"
        exit 1
    fi
    # Validation returns what clients and servers would be used and the userenv
    if [ "$do_validate" == 1 ]; then
        echo_clients_servers
        echo "userenv $userenv"
        exit
    fi
}

function process_k8s_opts() {
    local endpoint_opts="$1"
    for opt in `echo $endpoint_opts | sed -e 's/,/ /g'`; do
        arg=`echo $opt| awk -F: '{print $1}'`
        val=`echo $opt | awk -F: '{print $2}'`
        case "$arg" in
            client|server|clients|servers)
                addto_clients_servers "$arg" "$val"
                ;;
            host)
                k8s_host=$val
                ;;
            user)
                k8s_user=$val
                ;;
            userenv)
                userenv=$val
                ;;
            nodeSelector)
                if [ -e $val ]; then
                    nodeSelector=`cat $val`
                fi
                ;;
            securityContext)
                if [ -e $val ]; then
                    securityContext=`cat $val`
                else
                    exit_error "Could not find securityContext file $securityContext"
                fi
                ;;
            resources)
                if [ -e $val ]; then
                    resources=`cat $val`
                fi
                ;;
            *)
                exit_error "endpoint options $arg not supported"
                ;;
        esac
    done
}

function build_pod_spec() {
    local name=$1; shift
    local type=$1; shift
    local dir=$1; shift
    local json="$dir/$name.json"

    echo "{" >$json
    echo "  \"apiVersion\": \"v1\"," >>$json
    echo "  \"kind\": \"Pod\"," >>$json
    echo "  \"metadata\": {" >>$json
    echo "    \"name\": \"$pod_prefix-$name\"" >>$json
    echo "  }," >>$json
    echo "  \"spec\": {" >>$json
    echo "    \"restartPolicy\": \"Never\"," >>$json
    if [ "$type" == "cs" -a ! -z "$nodeSelector" ]; then
        echo -e "$nodeSelector," >>$json
    fi
    if [ "$type" == "master-tool" ]; then
        echo '    "tolerations": [' >>$json
        echo '        {' >>$json
        echo '            "key": "node-role.kubernetes.io/master",' >>$json
        echo '            "effect": "NoSchedule"' >>$json
        echo '        }' >>$json
        echo '    ],' >>$json
    fi
    if [ "$type" == "worker-tool" -o "$type" == "master-tool" ]; then
        echo "    \"nodeSelector\": {" >>$json
        echo "        \"kubernetes.io/hostname\": \"$name\"" >>$json
        echo "    }," >>$json
        echo "    \"hostPID\": true," >>$json
        echo "    \"hostNetwork\": true", >>$json
        echo "    \"hostIPC\": true," >>$json
    fi
    echo "    \"containers\": [" >>$json
    echo "      {" >>$json
    echo "        \"name\": \"$name\"," >>$json
    echo "        \"image\": \"$image\"," >>$json
    echo "        \"imagePullPolicy\": \"Always\"," >>$json
    echo "        \"env\": [" >>$json
    echo "          {" >>$json
    echo "            \"name\": \"rickshaw_host\"," >>$json
    echo "            \"value\": \"$hostname\"" >>$json
    echo "          }," >>$json
    echo "          {" >>$json
    echo "            \"name\": \"base_run_dir\"," >>$json
    echo "            \"value\": \"$base_run_dir\"" >>$json
    echo "          }," >>$json
    echo "          {" >>$json
    echo "            \"name\": \"cs_label\"," >>$json
    echo "            \"value\": \"$name\"" >>$json
    echo "          }," >>$json
    echo "          {" >>$json
    echo "            \"name\": \"endpoint_run_dir\"," >>$json
    echo "            \"value\": \"/endpoint-run\"" >>$json
    echo "          }," >>$json
    echo "          {" >>$json
    echo "            \"name\": \"roadblock_server\"," >>$json
    echo "            \"value\": \"$rb_server\"" >>$json
    echo "          }," >>$json
    echo "          {" >>$json
    echo "            \"name\": \"roadblock_passwd\"," >>$json
    echo "            \"value\": \"flubber\"" >>$json
    echo "          }," >>$json
    echo "          {" >>$json
    echo "            \"name\": \"roadblock_id\"," >>$json
    echo "            \"value\": \"$rb_id\"" >>$json
    echo "          }," >>$json
    echo "          {" >>$json
    echo "            \"name\": \"ssh_id\"," >>$json
    printf "            \"value\": \"" >>$json
    sed -z 's/\n/\\n/g' $config_dir/rickshaw_id.rsa >>$json
    echo "\"" >>$json
    echo "          }" >>$json
    echo "        ]" >>$json
    if [ "$type" == "worker-tool" -o "$type" == "master-tool" ]; then
        echo "        ,\"securityContext\": {" >>$json
        echo "          \"privileged\": true" >>$json
        echo "        }" >>$json 
    else
        if [ ! -z "$securityContext" ]; then
            echo -e ",$securityContext" >>$json
        fi
        if [ ! -z "$resources" ]; then
            echo -e ",$resources" >>$json
        fi
    fi
    echo "      }" >>$json
    let count=$count+1
    echo "    ]" >>$json
    echo "  }" >>$json
    echo "}" >>$json
}

function create_pods() {
    local type="$1"; shift
    local dir="$endpoint_run_dir/$type-pod-objects"
    local pods=""
    if [ -z "$*" ]; then
        exit_error "You must request one or more pods to create"
    fi
    mkdir -p "$dir"
    while [ ! -z "$1" ]; do
        local name="$1"; shift
        delete_pods "$name"
        build_pod_spec "$name" "$type" "$dir"
        if [ -e "$dir/$name.json" ]; then
            # TODO: the exit code does not work here, need to find a way to have it work
            cat "$dir/$name.json" | ssh $k8s_user@$k8s_host "kubectl create -f - 2>&1" >"$endpoint_run_dir/create-pod-output-$name.txt"
            if [ $? -gt 0 ]; then
                exit_error "Failed to create pod $name"
            fi
            pods+=" $name"
        else
            exit_error "Could not find $dir/$name.json to create pod: $create_output"
        fi
    done
    ssh $k8s_user@$k8s_host kubectl get pods 2>&1 >"$endpoint_run_dir/post-create-get-pods.txt"
    echo "$pods"
}

function verify_pods_running() {
    typeset -n ref1=$1; shift # caller-provided variable name (call-by-reference)
    ref1=""
    local kubectl_get_pods="$endpoint_run_dir/kubectl-get-pods.txt"
    declare -A unverified_pods
    declare -A verified_pods
    if [ -z "$1" ]; then
        exit_error "You must provide at least 1 pod to verify"
    fi
    while [ ! -z "$1" ]; do
        unverified_pods[$1]=1; shift
    done
    local num_pods=${#unverified_pods[@]}
    local count=0
    local max_attempts=12
    local abort=0
    local num_nonzero_exit=0
    local max_nonzero_exit=3
    until [ ${#unverified_pods[@]} -eq 0 -o $count -gt $max_attempts -o $abort -gt 0 ]; do
        sleep 5
        ssh $k8s_user@$k8s_host kubectl get pods -o wide | grep $pod_prefix >$kubectl_get_pods
        rc=$?
        if [ $rc -gt 0 ]; then
            let num_nonzero_exit=$num_nonzero_exit+1
            if [ $num_nonzero_exit -gt $max_nonzero_exit ]; then
                exit_error "kubectl-get-pods returns non-zero more than $max_nonzero_exit times, exiting"
            fi
        fi
        echo "kubectl get pods:"
        cat $kubectl_get_pods
        while read line; do
            echo "got this line: $line"
            local this_status=`echo $line | awk '{print $3}'`
            local this_pod=`echo $line | awk '{print $1}' | sed -e s/^$pod_prefix-//`
            local node=`echo $line | awk '{print $7}'`
            #if [ "$this_status" == "Error" -a ! -z "${unverified_pods[$this_pod]}" ]; then
            if echo "$this_status" | grep -q -i error; then
                # If just 1 pod is in error bail immediately
                abort=1
                echo "Pod $this_pod has this error: $this_status"
                echo "Getting 'describe pod' for $pod_prefix-$this_pod"
                ssh $k8s_user@$k8s_host kubectl describe pod $pod_prefix-$this_pod >"$endpoint_run_dir/kubectl-describe-pod-$this_pod.txt"
                break
            fi
            if [ "$this_status" == "Running" -a -z "${verified_pods[$this_pod]}" ]; then
                verified_pods[$this_pod]="$node"
                unset unverified_pods[$this_pod]
            fi
        done <$kubectl_get_pods
        let count=$count+1
    done
    if [ $abort -eq 1 -o $count -gt $max_attempts ]; then
        #TODO: send abort signal for endpoint-deploy roadblock
        echo "abort: $abort count: $count"
        exit_error "Failed to verify pods are running"
    fi
    declare -A nodes
    for i in ${verified_pods[@]}; do
        nodes[$i]=1
    done
    # var is assigned a space-separated list of nodes
    ref1+=" ${!nodes[@]}"
}

function get_pod_logs() {
    if [ -z "$1" ]; then
        exit_error "get_pod_logs(): at least 1 pod must be provided"
    fi
    while [ ! -z "$1" ]; do
        local name="$1"; shift
        echo "Getting logs from pod $name"
        pod_name="rickshaw-$name"
        ssh $k8s_user@$k8s_host kubectl logs $pod_name >"$client_server_logs_dir/$name.txt"
    done
}

function delete_pods() {
    if [ -z "$1" ]; then
        exit_error "delete_pods(): at least 1 pod must be provided"
    fi
    while [ ! -z "$1" ]; do
        local name="$1"; shift
        local existing_pod="`ssh $k8s_user@$k8s_host kubectl get pods | grep "^$pod_prefix-$name " | awk '{print $1}'`"
        if [ ! -z "$existing_pod" ]; then
            local delete_output=`ssh $k8s_user@$k8s_host "kubectl delete pod $existing_pod 2>&1"`
            if [ $? -gt 0 ]; then
                exit_error "Error deleting pod $existing_pod: $delete_output"
            fi
        fi
    done
}

function delete_old_pods() {
    local pods=`ssh $k8s_user@$k8s_host kubectl get pods -o wide | grep $pod_prefix | awk '{print $1}' | sed -e s/$pod_prefix-//`
    if [ ! -z "$pods" ]; then
        echo "Going to delete these old pods: $pods"
        delete_pods $pods
    else
        echo "No old pods to delete"
    fi
}

function get_k8s_config() {
    local kubectl_nodes_json="$endpoint_run_dir/kubectl-get-nodes.json"
    local kubectl_nodes_stderr="$endpoint_run_dir/kubectl-get-nodes.stderr"
    local k8s_nodes=`ssh -o StrictHostKeyChecking=no $k8s_user@$k8s_host kubectl get nodes`
    ssh $k8s_user@$k8s_host kubectl get nodes -o json >$kubectl_nodes_json 2>$kubectl_nodes_stderr
    local nr_nodes=`jq -r '.items | length' $kubectl_nodes_json`
    local masters=""
    local workers=""
    local node=""
    for node in `seq 0 $(expr $nr_nodes - 1)`; do
        local name=`jq -r '.items['$node'] | .metadata.name' $kubectl_nodes_json`
        #if [ "$(jq -r '.items['$node'] | .metadata.labels | has("node-role.kubernetes.io/master")' $kubectl_nodes_json)" == "true" ]; then
            #masters="$masters $name"
        #fi
        if [ "$(jq -r '.items['$node'] | .metadata.labels | has("node-role.kubernetes.io/worker")' $kubectl_nodes_json)" == "true" ]; then
            workers="$workers $name"
        fi
    done
    masters=`ssh $k8s_user@$k8s_host kubectl get nodes | grep " master " | grep " Ready " | grep -v "SchedulingDisabled" | awk '{print $1}'`
    echo "$workers" >"$endpoint_run_dir/worker-nodes.txt"
    echo "$masters" >"$endpoint_run_dir/master-nodes.txt"
}

process_opts "$@"
process_k8s_opts "$endpoint_opts"
init_common_dirs
k8s_req_check
base_req_check
get_k8s_config
delete_old_pods
echo "This endpoint to run these clients: ${clients[@]}"
cs_pods=`create_pods cs ${clients[@]}`
echo "These client pods were created: $cs_pods"
verify_pods_running active_worker_nodes $cs_pods
echo "These nodes are hosting the client-server pods: $active_worker_nodes"
echo "Working on creating worker-tool pods"
worker_tool_pods="`create_pods worker-tool $active_worker_nodes`"
echo "These worker-tool pods were created: $worker_tool_pods"
verify_pods_running tool_worker_nodes $worker_tool_pods
echo "These nodes are hosting the worker-tool pods: $tool_worker_nodes"
if [ 1 -eq 1 ]; then
    master_nodes=`cat "$endpoint_run_dir/master-nodes.txt"`
    echo "These nodes are masters: $master_nodes"
    echo "Working on creating these master-tool pods"
    master_tool_pods="`create_pods master-tool $master_nodes`"
    echo "These master-tool pods were created: $master_tool_pods"
    verify_pods_running tool_master_nodes $master_tool_pods
    echo "These nodes are hosting the master-tool pods: $master_tool_nodes"
fi
process_prebench_roadblocks $worker_tool_pods $master_tool_pods
process_bench_roadblocks
process_postbench_roadblocks $worker_tool_pods $master_tool_pods
get_pod_logs $worker_tool_pods $master_tool_pods $cs_pods
delete_pods $worker_tool_pods $master_tool_pods $cs_pods
process_final_roadblocks
